"use strict";(self.webpackChunkimdeepmind=self.webpackChunkimdeepmind||[]).push([[4899],{76643:(e,s,n)=>{n.r(s),n.d(s,{assets:()=>l,contentTitle:()=>o,default:()=>d,frontMatter:()=>r,metadata:()=>t,toc:()=>c});const t=JSON.parse('{"id":"ml/lang-chain/chat-models","title":"ChatModels","description":"In LangChain, ChatModels are abstractions over large language models that are optimized for conversational use cases. Instead of working only with plain text prompts, ChatModels handle structured conversational inputs such as a series of user and assistant messages. This allows us to build richer, more interactive applications like chatbots, assistants, and dialogue-based systems.","source":"@site/docs/ml/lang-chain/chat-models.md","sourceDirName":"ml/lang-chain","slug":"/ml/lang-chain/chat-models","permalink":"/docs/ml/lang-chain/chat-models","draft":false,"unlisted":false,"editUrl":"https://github.com/imdeepmind/imdeepmind.github.io/blob/main/docs/ml/lang-chain/chat-models.md","tags":[],"version":"current","lastUpdatedBy":"Abhishek Chatterjee","lastUpdatedAt":1758354436000,"sidebarPosition":3,"frontMatter":{"sidebar_position":3},"sidebar":"tutorialSidebar","previous":{"title":"PromptTemplates","permalink":"/docs/ml/lang-chain/promt-templates"},"next":{"title":"Chains","permalink":"/docs/ml/lang-chain/chains"}}');var a=n(74848),i=n(28453);const r={sidebar_position:3},o="ChatModels",l={},c=[{value:"Core Concepts of ChatModels",id:"core-concepts-of-chatmodels",level:2},{value:"What ChatModels are",id:"what-chatmodels-are",level:3},{value:"Why ChatModels matter",id:"why-chatmodels-matter",level:3},{value:"ChatMessage Abstraction",id:"chatmessage-abstraction",level:2},{value:"Flow of ChatModels",id:"flow-of-chatmodels",level:2},{value:"Using ChatModels",id:"using-chatmodels",level:2},{value:"Streaming with ChatModels",id:"streaming-with-chatmodels",level:2},{value:"ChatModels in Chains",id:"chatmodels-in-chains",level:2},{value:"Benefits of ChatModels",id:"benefits-of-chatmodels",level:2}];function h(e){const s={code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",li:"li",mermaid:"mermaid",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,i.R)(),...e.components};return(0,a.jsxs)(a.Fragment,{children:[(0,a.jsx)(s.header,{children:(0,a.jsx)(s.h1,{id:"chatmodels",children:"ChatModels"})}),"\n",(0,a.jsxs)(s.p,{children:["In LangChain, ",(0,a.jsx)(s.strong,{children:"ChatModels"})," are abstractions over large language models that are optimized for conversational use cases. Instead of working only with plain text prompts, ChatModels handle structured conversational inputs such as a series of user and assistant messages. This allows us to build richer, more interactive applications like chatbots, assistants, and dialogue-based systems."]}),"\n",(0,a.jsxs)(s.p,{children:["ChatModels differ from regular LLMs in that they expect and return ",(0,a.jsx)(s.strong,{children:"message objects"}),", not just strings. These message objects give us more control over how context is preserved and managed."]}),"\n",(0,a.jsx)(s.h2,{id:"core-concepts-of-chatmodels",children:"Core Concepts of ChatModels"}),"\n",(0,a.jsx)(s.h3,{id:"what-chatmodels-are",children:"What ChatModels are"}),"\n",(0,a.jsx)(s.p,{children:"ChatModels wrap around LLMs but use a structured format. Each conversational exchange is represented as a sequence of messages. Messages can belong to different roles such as:"}),"\n",(0,a.jsxs)(s.ul,{children:["\n",(0,a.jsxs)(s.li,{children:[(0,a.jsx)(s.strong,{children:"System"})," \u2013 defines behavior or context for the assistant."]}),"\n",(0,a.jsxs)(s.li,{children:[(0,a.jsx)(s.strong,{children:"User"})," \u2013 represents human inputs."]}),"\n",(0,a.jsxs)(s.li,{children:[(0,a.jsx)(s.strong,{children:"Assistant"})," \u2013 represents model responses."]}),"\n",(0,a.jsxs)(s.li,{children:[(0,a.jsx)(s.strong,{children:"AI / Function / Tool"})," \u2013 used when integrating with external systems."]}),"\n"]}),"\n",(0,a.jsx)(s.h3,{id:"why-chatmodels-matter",children:"Why ChatModels matter"}),"\n",(0,a.jsxs)(s.ul,{children:["\n",(0,a.jsx)(s.li,{children:"They allow multi-turn conversations with structured memory."}),"\n",(0,a.jsx)(s.li,{children:"They enable role-specific prompting (system vs user vs assistant)."}),"\n",(0,a.jsx)(s.li,{children:"They integrate seamlessly with Chains and Agents for conversational AI."}),"\n"]}),"\n",(0,a.jsx)(s.h2,{id:"chatmessage-abstraction",children:"ChatMessage Abstraction"}),"\n",(0,a.jsxs)(s.p,{children:["In LangChain, each message is represented as a ",(0,a.jsx)(s.code,{children:"BaseMessage"}),". Common message types include:"]}),"\n",(0,a.jsxs)(s.ul,{children:["\n",(0,a.jsxs)(s.li,{children:[(0,a.jsx)(s.code,{children:"SystemMessage"})," \u2013 defines global instructions."]}),"\n",(0,a.jsxs)(s.li,{children:[(0,a.jsx)(s.code,{children:"HumanMessage"})," \u2013 carries user queries."]}),"\n",(0,a.jsxs)(s.li,{children:[(0,a.jsx)(s.code,{children:"AIMessage"})," \u2013 carries model replies."]}),"\n"]}),"\n",(0,a.jsx)(s.pre,{children:(0,a.jsx)(s.code,{className:"language-python",children:'from langchain.schema import SystemMessage, HumanMessage, AIMessage\n\nmessages = [\n    SystemMessage(content="You are a helpful assistant."),\n    HumanMessage(content="Who won the FIFA World Cup in 2018?"),\n    AIMessage(content="France won the FIFA World Cup in 2018.")\n]\n'})}),"\n",(0,a.jsx)(s.p,{children:"This structure is richer than plain strings and lets us encode context more clearly."}),"\n",(0,a.jsx)(s.h2,{id:"flow-of-chatmodels",children:"Flow of ChatModels"}),"\n",(0,a.jsx)(s.p,{children:"We can visualize how ChatModels process input and generate output:"}),"\n",(0,a.jsx)("div",{style:{textAlign:"center"},children:(0,a.jsx)(s.mermaid,{value:"flowchart LR\n    A[User Input] --\x3e B[HumanMessage]\n    B --\x3e C[ChatModel]\n    D[SystemMessage] --\x3e C\n    C --\x3e E[AIMessage]\n    E --\x3e F[Response to User]"})}),"\n",(0,a.jsx)(s.p,{children:"Here:"}),"\n",(0,a.jsxs)(s.ul,{children:["\n",(0,a.jsxs)(s.li,{children:["A user input is wrapped into a ",(0,a.jsx)(s.code,{children:"HumanMessage"}),"."]}),"\n",(0,a.jsxs)(s.li,{children:["Context/instructions come from ",(0,a.jsx)(s.code,{children:"SystemMessage"}),"."]}),"\n",(0,a.jsx)(s.li,{children:"The ChatModel processes everything."}),"\n",(0,a.jsxs)(s.li,{children:["It returns an ",(0,a.jsx)(s.code,{children:"AIMessage"}),"."]}),"\n"]}),"\n",(0,a.jsx)(s.h2,{id:"using-chatmodels",children:"Using ChatModels"}),"\n",(0,a.jsxs)(s.p,{children:["A simple usage example with OpenAI\u2019s ",(0,a.jsx)(s.code,{children:"gpt-3.5-turbo"})," (via LangChain):"]}),"\n",(0,a.jsx)(s.pre,{children:(0,a.jsx)(s.code,{className:"language-python",children:'from langchain_openai import ChatOpenAI\nfrom langchain.schema import HumanMessage, SystemMessage\n\nchat = ChatOpenAI(temperature=0)\n\nmessages = [\n    SystemMessage(content="You are a wise mentor."),\n    HumanMessage(content="Explain recursion in simple terms.")\n]\n\nresponse = chat.invoke(messages)\nprint(response.content)\n'})}),"\n",(0,a.jsx)(s.p,{children:"Output could be:"}),"\n",(0,a.jsx)(s.pre,{children:(0,a.jsx)(s.code,{className:"language-text",children:"Recursion is when a function calls itself to solve smaller versions of a problem until it reaches a base case.\n"})}),"\n",(0,a.jsx)(s.h2,{id:"streaming-with-chatmodels",children:"Streaming with ChatModels"}),"\n",(0,a.jsx)(s.p,{children:"One advantage of ChatModels is that they can stream responses token by token. This is useful for real-time applications like chat interfaces."}),"\n",(0,a.jsx)(s.pre,{children:(0,a.jsx)(s.code,{className:"language-python",children:'for chunk in chat.stream(messages):\n    print(chunk.content, end="")\n'})}),"\n",(0,a.jsx)(s.p,{children:"This lets us display responses as they are generated instead of waiting for completion."}),"\n",(0,a.jsx)(s.h2,{id:"chatmodels-in-chains",children:"ChatModels in Chains"}),"\n",(0,a.jsxs)(s.p,{children:["We can combine ChatModels with ",(0,a.jsx)(s.strong,{children:"PromptTemplates"})," and Chains to create more structured workflows. For example, wrapping a prompt inside a conversational flow:"]}),"\n",(0,a.jsx)(s.pre,{children:(0,a.jsx)(s.code,{className:"language-python",children:'from langchain.prompts import ChatPromptTemplate\nfrom langchain.chains import LLMChain\n\nprompt = ChatPromptTemplate.from_messages([\n    ("system", "You are a creative assistant."),\n    ("human", "Suggest three taglines for a {product}.")\n])\n\nchat_model = ChatOpenAI(temperature=0.7)\nchain = LLMChain(llm=chat_model, prompt=prompt)\n\nresult = chain.run(product="eco-friendly water bottle")\nprint(result)\n'})}),"\n",(0,a.jsx)(s.p,{children:"This generates a conversational output where the assistant role is automatically handled."}),"\n",(0,a.jsx)(s.h2,{id:"benefits-of-chatmodels",children:"Benefits of ChatModels"}),"\n",(0,a.jsxs)(s.ul,{children:["\n",(0,a.jsxs)(s.li,{children:[(0,a.jsx)(s.strong,{children:"Role-based messaging"})," \u2013 clear distinction between system, user, and assistant inputs."]}),"\n",(0,a.jsxs)(s.li,{children:[(0,a.jsx)(s.strong,{children:"Structured conversations"})," \u2013 better for multi-turn dialogue."]}),"\n",(0,a.jsxs)(s.li,{children:[(0,a.jsx)(s.strong,{children:"Streaming support"})," \u2013 suitable for interactive apps."]}),"\n",(0,a.jsxs)(s.li,{children:[(0,a.jsx)(s.strong,{children:"Integration with Chains and Agents"})," \u2013 ideal for complex conversational workflows."]}),"\n",(0,a.jsxs)(s.li,{children:[(0,a.jsx)(s.strong,{children:"Consistency"})," \u2013 ensures prompts are more predictable and context-aware."]}),"\n"]})]})}function d(e={}){const{wrapper:s}={...(0,i.R)(),...e.components};return s?(0,a.jsx)(s,{...e,children:(0,a.jsx)(h,{...e})}):h(e)}},28453:(e,s,n)=>{n.d(s,{R:()=>r,x:()=>o});var t=n(96540);const a={},i=t.createContext(a);function r(e){const s=t.useContext(i);return t.useMemo((function(){return"function"==typeof e?e(s):{...s,...e}}),[s,e])}function o(e){let s;return s=e.disableParentContext?"function"==typeof e.components?e.components(a):e.components||a:r(e.components),t.createElement(i.Provider,{value:s},e.children)}}}]);