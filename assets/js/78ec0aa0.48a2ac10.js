"use strict";(self.webpackChunkimdeepmind=self.webpackChunkimdeepmind||[]).push([[9028],{57522:(e,n,t)=>{t.r(n),t.d(n,{assets:()=>h,contentTitle:()=>l,default:()=>d,frontMatter:()=>r,metadata:()=>a,toc:()=>o});const a=JSON.parse('{"id":"ml/mcp/langchain","title":"LangChain","description":"This note explains how LangChain can be used with MCP servers, using a Weather + Weather News example, and provides a technical overview with diagrams.","source":"@site/docs/ml/mcp/langchain.md","sourceDirName":"ml/mcp","slug":"/ml/mcp/langchain","permalink":"/docs/ml/mcp/langchain","draft":false,"unlisted":false,"editUrl":"https://github.com/imdeepmind/imdeepmind.github.io/blob/main/docs/ml/mcp/langchain.md","tags":[],"version":"current","lastUpdatedBy":"Abhishek Chatterjee","lastUpdatedAt":1755179325000,"sidebarPosition":4,"frontMatter":{"sidebar_position":4},"sidebar":"tutorialSidebar","previous":{"title":"Architecture","permalink":"/docs/ml/mcp/architecture"},"next":{"title":"Regular Expressions (RegEx)","permalink":"/docs/other/regex"}}');var i=t(74848),s=t(28453);const r={sidebar_position:4},l="LangChain",h={},o=[{value:"Introduction to LangChain",id:"introduction-to-langchain",level:2},{value:"MCP Recap",id:"mcp-recap",level:2},{value:"Where LangChain Fits",id:"where-langchain-fits",level:2},{value:"Example: Weather + Weather News",id:"example-weather--weather-news",level:2},{value:"How LangChain Handles It",id:"how-langchain-handles-it",level:2},{value:"Step-by-Step Flow",id:"step-by-step-flow",level:3},{value:"Under the Hood",id:"under-the-hood",level:2},{value:"Architecture Diagram",id:"architecture-diagram",level:2},{value:"Detailed Flow Diagram",id:"detailed-flow-diagram",level:2},{value:"Why LangChain is Useful with MCP",id:"why-langchain-is-useful-with-mcp",level:2}];function c(e){const n={blockquote:"blockquote",code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",li:"li",mermaid:"mermaid",ol:"ol",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,s.R)(),...e.components};return(0,i.jsxs)(i.Fragment,{children:[(0,i.jsx)(n.header,{children:(0,i.jsx)(n.h1,{id:"langchain",children:"LangChain"})}),"\n",(0,i.jsx)(n.p,{children:"This note explains how LangChain can be used with MCP servers, using a Weather + Weather News example, and provides a technical overview with diagrams."}),"\n",(0,i.jsx)(n.h2,{id:"introduction-to-langchain",children:"Introduction to LangChain"}),"\n",(0,i.jsx)(n.p,{children:"LangChain is a framework that helps Large Language Models (LLMs) interact with external data sources, tools, and APIs in a structured way. Its main functions are:"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"Wrapping APIs/tools so LLMs can understand and call them."}),"\n",(0,i.jsx)(n.li,{children:"Deciding which tool to call and when, based on user requests."}),"\n",(0,i.jsx)(n.li,{children:"Orchestrating multi-step reasoning so LLMs can chain different tool calls together."}),"\n"]}),"\n",(0,i.jsx)(n.p,{children:'Without LangChain, an LLM would need a custom integration for every API. With LangChain, we can register APIs (including MCP servers) as "tools," describe what they do, and let LangChain handle tool selection, argument parsing, and result formatting.'}),"\n",(0,i.jsx)(n.h2,{id:"mcp-recap",children:"MCP Recap"}),"\n",(0,i.jsxs)(n.p,{children:["MCP (Model Context Protocol) is a protocol that allows us to create servers exposing capabilities (e.g., ",(0,i.jsx)(n.code,{children:"get_weather"}),", ",(0,i.jsx)(n.code,{children:"get_weather_news"}),") with metadata so an LLM knows:"]}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"What functions exist"}),"\n",(0,i.jsx)(n.li,{children:"What parameters they take"}),"\n",(0,i.jsx)(n.li,{children:"What they return"}),"\n"]}),"\n",(0,i.jsx)(n.p,{children:"When we connect an MCP server to an LLM, the LLM can directly call those MCP tools."}),"\n",(0,i.jsx)(n.h2,{id:"where-langchain-fits",children:"Where LangChain Fits"}),"\n",(0,i.jsx)(n.p,{children:"If we have multiple MCP servers or want more control and reasoning, LangChain acts as:"}),"\n",(0,i.jsxs)(n.ol,{children:["\n",(0,i.jsx)(n.li,{children:"A middle layer between the LLM and MCP servers."}),"\n",(0,i.jsx)(n.li,{children:"A tool manager \u2014 it registers MCP functions as LangChain tools."}),"\n",(0,i.jsx)(n.li,{children:"An orchestrator \u2014 if a query needs multiple calls, LangChain figures that out."}),"\n"]}),"\n",(0,i.jsx)(n.h2,{id:"example-weather--weather-news",children:"Example: Weather + Weather News"}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.strong,{children:"We have:"})}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:["Weather MCP Server: ",(0,i.jsx)(n.code,{children:"get_weather(city, date)"})," \u2192 Returns temperature and rain status."]}),"\n",(0,i.jsxs)(n.li,{children:["Weather News MCP Server: ",(0,i.jsx)(n.code,{children:"get_weather_news(city)"})," \u2192 Returns latest rain-related news."]}),"\n"]}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.strong,{children:"User query:"})}),"\n",(0,i.jsxs)(n.blockquote,{children:["\n",(0,i.jsx)(n.p,{children:"Do we need an umbrella in Mumbai tomorrow and what\u2019s the latest news about the rain?"}),"\n"]}),"\n",(0,i.jsx)(n.h2,{id:"how-langchain-handles-it",children:"How LangChain Handles It"}),"\n",(0,i.jsx)(n.h3,{id:"step-by-step-flow",children:"Step-by-Step Flow"}),"\n",(0,i.jsxs)(n.ol,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"User Input \u2192 LangChain LLM Chain"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"LangChain sends the user\u2019s query to the LLM with a system prompt listing all tools from both MCP servers."}),"\n"]}),"\n"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"LLM Decides Tools to Call"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:["The LLM parses the query and decides:","\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:["Call ",(0,i.jsx)(n.code,{children:'get_weather("Mumbai", "2025-08-15")'})," to check rain."]}),"\n",(0,i.jsxs)(n.li,{children:["Call ",(0,i.jsx)(n.code,{children:'get_weather_news("Mumbai")'})," for latest news."]}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"LangChain Executes Calls"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"LangChain uses its registered tool definitions to call the Weather MCP Server and the Weather News MCP Server."}),"\n"]}),"\n"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Results Returned"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:["Weather MCP \u2192 ",(0,i.jsx)(n.code,{children:'{ "temp": 28, "rain": true }'})]}),"\n",(0,i.jsxs)(n.li,{children:["News MCP \u2192 ",(0,i.jsx)(n.code,{children:'"Heavy rainfall expected in Mumbai tomorrow\u2026"'})]}),"\n"]}),"\n"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"LLM Final Response"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:["LangChain passes both results back to the LLM, which combines them into a natural response:","\n",(0,i.jsxs)(n.blockquote,{children:["\n",(0,i.jsx)(n.p,{children:"Yes, we\u2019ll need an umbrella tomorrow in Mumbai. Heavy rainfall is expected according to the latest news."}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,i.jsx)(n.h2,{id:"under-the-hood",children:"Under the Hood"}),"\n",(0,i.jsx)(n.p,{children:"LangChain internally does:"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:["\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.strong,{children:"Tool Registration:"})}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:'from langchain.tools import Tool\n\nTool(\n    name="get_weather",\n    func=get_weather_from_mcp,\n    description="Get temperature and rain status for a city and date."\n)\n'})}),"\n",(0,i.jsx)(n.p,{children:"It wraps the MCP API so the LLM can call it."}),"\n"]}),"\n",(0,i.jsxs)(n.li,{children:["\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Prompt Engineering:"}),"\nIt generates a system message like:"]}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-text",children:"We are an assistant with access to the following tools:\n1. get_weather(city, date) \u2192 Get temperature and rain status.\n2. get_weather_news(city) \u2192 Get latest weather news.\n"})}),"\n"]}),"\n",(0,i.jsxs)(n.li,{children:["\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Tool Selection:"}),"\nThe LLM uses few-shot examples and descriptions to choose the right tool."]}),"\n"]}),"\n",(0,i.jsxs)(n.li,{children:["\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Execution Orchestration:"}),"\nLangChain intercepts the tool call JSON, executes it, and returns the result to the LLM for the next step."]}),"\n"]}),"\n"]}),"\n",(0,i.jsx)(n.h2,{id:"architecture-diagram",children:"Architecture Diagram"}),"\n",(0,i.jsx)(n.mermaid,{value:"flowchart TD\n    User[User Query] --\x3e LC[LangChain LLM Orchestration]\n    LC --\x3e LLM[LLM Model]\n    LLM --\x3e|Tool Call| LC\n    LC --\x3e|Call via MCP| MCP1[Weather MCP Server]\n    LC --\x3e|Call via MCP| MCP2[Weather News MCP Server]\n    MCP1 --\x3e LC\n    MCP2 --\x3e LC\n    LC --\x3e LLM\n    LLM --\x3e Final[Final Combined Response]"}),"\n",(0,i.jsx)(n.h2,{id:"detailed-flow-diagram",children:"Detailed Flow Diagram"}),"\n",(0,i.jsx)(n.mermaid,{value:'sequenceDiagram\n    participant U as User\n    participant LC as LangChain\n    participant LLM as LLM\n    participant MCP1 as Weather MCP\n    participant MCP2 as Weather News MCP\n\n    U->>LC: "Do we need an umbrella in Mumbai tomorrow and news about rain?"\n    LC->>LLM: Send query + tool descriptions\n    LLM--\x3e>LC: Call get_weather("Mumbai", "2025-08-15")\n    LC->>MCP1: get_weather("Mumbai", "2025-08-15")\n    MCP1--\x3e>LC: {temp: 28, rain: true}\n\n    LLM--\x3e>LC: Call get_weather_news("Mumbai")\n    LC->>MCP2: get_weather_news("Mumbai")\n    MCP2--\x3e>LC: "Heavy rainfall expected..."\n\n    LC->>LLM: Return both results\n    LLM--\x3e>LC: Form final natural language answer\n    LC--\x3e>U: "Yes, we\u2019ll need an umbrella..."'}),"\n",(0,i.jsx)(n.h2,{id:"why-langchain-is-useful-with-mcp",children:"Why LangChain is Useful with MCP"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"Combines multiple MCP servers without writing glue code."}),"\n",(0,i.jsx)(n.li,{children:"Multi-step reasoning \u2014 LLM can call tools in sequence."}),"\n",(0,i.jsx)(n.li,{children:"Consistent interface \u2014 MCP just becomes another \u201ctool source.\u201d"}),"\n",(0,i.jsx)(n.li,{children:"Easy to swap LLMs \u2014 LangChain works with OpenAI, Anthropic, etc."}),"\n",(0,i.jsx)(n.li,{children:"Extra features \u2014 logging, retries, parallel calls, caching."}),"\n"]})]})}function d(e={}){const{wrapper:n}={...(0,s.R)(),...e.components};return n?(0,i.jsx)(n,{...e,children:(0,i.jsx)(c,{...e})}):c(e)}},28453:(e,n,t)=>{t.d(n,{R:()=>r,x:()=>l});var a=t(96540);const i={},s=a.createContext(i);function r(e){const n=a.useContext(s);return a.useMemo((function(){return"function"==typeof e?e(n):{...n,...e}}),[n,e])}function l(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(i):e.components||i:r(e.components),a.createElement(s.Provider,{value:n},e.children)}}}]);