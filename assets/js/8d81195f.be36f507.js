"use strict";(self.webpackChunkimdeepmind=self.webpackChunkimdeepmind||[]).push([[909],{5271:(e,n,i)=>{i.r(n),i.d(n,{assets:()=>r,contentTitle:()=>o,default:()=>p,frontMatter:()=>l,metadata:()=>a,toc:()=>h});const a=JSON.parse('{"id":"ml/lang-chain/chains","title":"Chains","description":"In LangChain, Chains are sequences of steps that process inputs and produce outputs, typically involving one or more language model calls combined with other utilities. Instead of working directly with raw prompts and models, Chains allow us to structure workflows. This makes our applications more reusable, modular, and easier to maintain.","source":"@site/docs/ml/lang-chain/chains.md","sourceDirName":"ml/lang-chain","slug":"/ml/lang-chain/chains","permalink":"/docs/ml/lang-chain/chains","draft":false,"unlisted":false,"editUrl":"https://github.com/imdeepmind/imdeepmind.github.io/blob/main/docs/ml/lang-chain/chains.md","tags":[],"version":"current","lastUpdatedBy":"Abhishek Chatterjee","lastUpdatedAt":1758354436000,"sidebarPosition":4,"frontMatter":{"sidebar_position":4},"sidebar":"tutorialSidebar","previous":{"title":"ChatModels","permalink":"/docs/ml/lang-chain/chat-models"},"next":{"title":"LCEL","permalink":"/docs/ml/lang-chain/lcel"}}');var t=i(74848),s=i(28453);const l={sidebar_position:4},o="Chains",r={},h=[{value:"Core Concepts of Chains",id:"core-concepts-of-chains",level:2},{value:"What Chains are",id:"what-chains-are",level:3},{value:"Why Chains matter",id:"why-chains-matter",level:3},{value:"Basic Example of a Chain",id:"basic-example-of-a-chain",level:2},{value:"Flow of a Chain",id:"flow-of-a-chain",level:2},{value:"Types of Chains",id:"types-of-chains",level:2},{value:"Example of SequentialChain",id:"example-of-sequentialchain",level:2},{value:"Flow of SequentialChain",id:"flow-of-sequentialchain",level:2},{value:"RouterChain Example",id:"routerchain-example",level:2},{value:"Benefits of Chains",id:"benefits-of-chains",level:2},{value:"Sample code: Summarization using LangChain",id:"sample-code-summarization-using-langchain",level:2},{value:"Explanation of the workflow",id:"explanation-of-the-workflow",level:3}];function c(e){const n={code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",li:"li",mermaid:"mermaid",ol:"ol",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,s.R)(),...e.components};return(0,t.jsxs)(t.Fragment,{children:[(0,t.jsx)(n.header,{children:(0,t.jsx)(n.h1,{id:"chains",children:"Chains"})}),"\n",(0,t.jsxs)(n.p,{children:["In LangChain, ",(0,t.jsx)(n.strong,{children:"Chains"})," are sequences of steps that process inputs and produce outputs, typically involving one or more language model calls combined with other utilities. Instead of working directly with raw prompts and models, Chains allow us to structure workflows. This makes our applications more reusable, modular, and easier to maintain."]}),"\n",(0,t.jsxs)(n.p,{children:["A Chain can be as simple as a ",(0,t.jsx)(n.strong,{children:"single LLM call"})," or as complex as a ",(0,t.jsx)(n.strong,{children:"multi-step pipeline"})," involving prompts, tools, memory, and custom logic."]}),"\n",(0,t.jsx)(n.h2,{id:"core-concepts-of-chains",children:"Core Concepts of Chains"}),"\n",(0,t.jsx)(n.h3,{id:"what-chains-are",children:"What Chains are"}),"\n",(0,t.jsx)(n.p,{children:"Chains abstract the orchestration of LLM calls and related tasks. They provide a framework for:"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"Defining a sequence of steps."}),"\n",(0,t.jsx)(n.li,{children:"Managing inputs and outputs between components."}),"\n",(0,t.jsx)(n.li,{children:"Reusing logic across different applications."}),"\n"]}),"\n",(0,t.jsx)(n.h3,{id:"why-chains-matter",children:"Why Chains matter"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:["They make applications ",(0,t.jsx)(n.strong,{children:"structured and reproducible"}),"."]}),"\n",(0,t.jsxs)(n.li,{children:["They allow ",(0,t.jsx)(n.strong,{children:"integration of multiple components"})," (LLMs, prompts, retrievers, databases, tools)."]}),"\n",(0,t.jsxs)(n.li,{children:["They reduce ",(0,t.jsx)(n.strong,{children:"boilerplate code"})," and simplify debugging."]}),"\n"]}),"\n",(0,t.jsx)(n.h2,{id:"basic-example-of-a-chain",children:"Basic Example of a Chain"}),"\n",(0,t.jsxs)(n.p,{children:["A very simple Chain is the ",(0,t.jsx)(n.code,{children:"LLMChain"}),". It combines a ",(0,t.jsx)(n.code,{children:"PromptTemplate"})," with an LLM."]}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-python",children:'from langchain.prompts import PromptTemplate\nfrom langchain.chains import LLMChain\nfrom langchain_openai import OpenAI\n\nllm = OpenAI(temperature=0)\n\nprompt = PromptTemplate(\n    input_variables=["product"],\n    template="What is a good name for a company that makes {product}?"\n)\n\nchain = LLMChain(llm=llm, prompt=prompt)\n\nresult = chain.run(product="colorful socks")\nprint(result)\n'})}),"\n",(0,t.jsx)(n.p,{children:"Here:"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.code,{children:"PromptTemplate"})," defines the structure."]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.code,{children:"LLMChain"})," binds it with the LLM."]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.code,{children:"run()"})," executes the Chain."]}),"\n"]}),"\n",(0,t.jsx)(n.h2,{id:"flow-of-a-chain",children:"Flow of a Chain"}),"\n",(0,t.jsx)(n.p,{children:"We can visualize the flow of a simple Chain:"}),"\n",(0,t.jsx)("div",{style:{textAlign:"center"},children:(0,t.jsx)(n.mermaid,{value:"flowchart LR\n    A[Input Variables] --\x3e B[PromptTemplate]\n    B --\x3e C[LLM]\n    C --\x3e D[Output Text]"})}),"\n",(0,t.jsx)(n.p,{children:"This shows how user input is transformed by a prompt, processed by the LLM, and then returned as output."}),"\n",(0,t.jsx)(n.h2,{id:"types-of-chains",children:"Types of Chains"}),"\n",(0,t.jsx)(n.p,{children:"There are several types of Chains in LangChain, each serving different use cases:"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"LLMChain"})," \u2013 a single LLM call with a prompt."]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"SimpleSequentialChain"})," \u2013 a linear sequence where the output of one chain is passed as input to the next."]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"SequentialChain"})," \u2013 like ",(0,t.jsx)(n.code,{children:"SimpleSequentialChain"})," but allows multiple inputs and outputs."]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"RouterChain"})," \u2013 routes inputs to different chains depending on conditions."]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"TransformChain"})," \u2013 applies a Python function as a transformation step inside a chain."]}),"\n"]}),"\n",(0,t.jsx)(n.h2,{id:"example-of-sequentialchain",children:"Example of SequentialChain"}),"\n",(0,t.jsx)(n.p,{children:"We can combine multiple steps into one flow."}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-python",children:'from langchain.chains import LLMChain, SequentialChain\nfrom langchain.prompts import PromptTemplate\nfrom langchain_openai import OpenAI\n\nllm = OpenAI(temperature=0)\n\n# Step 1: Generate a company name\nprompt1 = PromptTemplate(\n    input_variables=["product"],\n    template="What is a good name for a company that makes {product}?"\n)\nchain1 = LLMChain(llm=llm, prompt=prompt1, output_key="company_name")\n\n# Step 2: Generate a slogan based on the name\nprompt2 = PromptTemplate(\n    input_variables=["company_name"],\n    template="Write a creative tagline for {company_name}."\n)\nchain2 = LLMChain(llm=llm, prompt=prompt2, output_key="tagline")\n\n# Combine them\noverall_chain = SequentialChain(\n    chains=[chain1, chain2],\n    input_variables=["product"],\n    output_variables=["company_name", "tagline"]\n)\n\nresult = overall_chain.run(product="eco-friendly shoes")\nprint(result)\n'})}),"\n",(0,t.jsx)(n.p,{children:"Here:"}),"\n",(0,t.jsxs)(n.ol,{children:["\n",(0,t.jsx)(n.li,{children:"The first chain generates a company name."}),"\n",(0,t.jsx)(n.li,{children:"The second chain generates a tagline based on that name."}),"\n",(0,t.jsx)(n.li,{children:"The SequentialChain orchestrates the whole process."}),"\n"]}),"\n",(0,t.jsx)(n.h2,{id:"flow-of-sequentialchain",children:"Flow of SequentialChain"}),"\n",(0,t.jsx)("div",{style:{textAlign:"center"},children:(0,t.jsx)(n.mermaid,{value:"flowchart LR\n    A[Product Input] --\x3e B[Chain 1: Generate Company Name]\n    B --\x3e C[Chain 2: Generate Tagline]\n    C --\x3e D[Final Output]"})}),"\n",(0,t.jsx)(n.p,{children:"This shows how outputs of one chain become inputs to the next."}),"\n",(0,t.jsx)(n.h2,{id:"routerchain-example",children:"RouterChain Example"}),"\n",(0,t.jsx)(n.p,{children:"Sometimes we want different prompts for different cases. A RouterChain can decide which chain to execute."}),"\n",(0,t.jsx)(n.p,{children:"For example:"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"If the input asks for translation, route to a translation chain."}),"\n",(0,t.jsx)(n.li,{children:"If the input asks for summarization, route to a summarization chain."}),"\n"]}),"\n",(0,t.jsx)(n.p,{children:"This adds flexibility and intelligence in choosing the right path."}),"\n",(0,t.jsx)(n.h2,{id:"benefits-of-chains",children:"Benefits of Chains"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Modularity"})," \u2013 we can compose small building blocks."]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Reusability"})," \u2013 chains can be reused across projects."]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Scalability"})," \u2013 easy to extend with more steps."]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Debugging"})," \u2013 intermediate outputs can be inspected."]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Integration"})," \u2013 chains connect LLMs with external tools and memory."]}),"\n"]}),"\n",(0,t.jsx)(n.h2,{id:"sample-code-summarization-using-langchain",children:"Sample code: Summarization using LangChain"}),"\n",(0,t.jsx)(n.p,{children:"Below is a minimal example showing how to use Prompt Templates, ChatModels, and Chains together to perform text summarization."}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-python",children:'from langchain_openai import ChatOpenAI\nfrom langchain.prompts import PromptTemplate\nfrom langchain.chains import LLMChain\n\n# Step 1: Define the prompt template\ntemplate = """\nSummarize the following text in 2-3 sentences:\n{text}\n"""\nprompt = PromptTemplate(template=template, input_variables=["text"])\n\n# Step 2: Load a chat model\nchat_model = ChatOpenAI(model="gpt-3.5-turbo", temperature=0)\n\n# Step 3: Create a chain combining prompt and model\nsummarization_chain = LLMChain(llm=chat_model, prompt=prompt)\n\n# Step 4: Provide input text\ninput_text = """\nLangChain is an open-source framework that helps developers build applications using large language models.\nIt provides abstractions for prompts, chains, agents, and memory, making it easier to create advanced AI systems.\nLangChain is widely used for chatbots, question answering, document analysis, and workflow automation.\n"""\n\n# Step 5: Run the chain\nsummary = summarization_chain.run({"text": input_text})\nprint(summary)\n'})}),"\n",(0,t.jsx)(n.h3,{id:"explanation-of-the-workflow",children:"Explanation of the workflow"}),"\n",(0,t.jsxs)(n.ol,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"PromptTemplate"})," defines the summarization task with a variable ",(0,t.jsx)(n.code,{children:"{text}"}),"."]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"ChatOpenAI"})," loads the chat model (GPT-3.5 in this case)."]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"LLMChain"})," connects the prompt with the model, forming a simple chain."]}),"\n",(0,t.jsx)(n.li,{children:"The input text is passed into the chain."}),"\n",(0,t.jsx)(n.li,{children:"The model processes the filled-in prompt and returns a concise summary."}),"\n"]})]})}function p(e={}){const{wrapper:n}={...(0,s.R)(),...e.components};return n?(0,t.jsx)(n,{...e,children:(0,t.jsx)(c,{...e})}):c(e)}},28453:(e,n,i)=>{i.d(n,{R:()=>l,x:()=>o});var a=i(96540);const t={},s=a.createContext(t);function l(e){const n=a.useContext(s);return a.useMemo((function(){return"function"==typeof e?e(n):{...n,...e}}),[n,e])}function o(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(t):e.components||t:l(e.components),a.createElement(s.Provider,{value:n},e.children)}}}]);